{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e74d5577-df2d-4d38-b98c-6860cb3bab8c",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9ddb6b3-053c-4fc9-a182-ec4df2f03dea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T08:02:38.166713Z",
     "iopub.status.busy": "2025-07-08T08:02:38.166393Z",
     "iopub.status.idle": "2025-07-08T08:02:38.169480Z",
     "shell.execute_reply": "2025-07-08T08:02:38.168998Z",
     "shell.execute_reply.started": "2025-07-08T08:02:38.166691Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81202ca8-8317-47a4-93dc-fc3f9d1d20fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T08:16:52.993324Z",
     "iopub.status.busy": "2025-07-08T08:16:52.993053Z",
     "iopub.status.idle": "2025-07-08T08:16:52.999147Z",
     "shell.execute_reply": "2025-07-08T08:16:52.998321Z",
     "shell.execute_reply.started": "2025-07-08T08:16:52.993299Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import sys_append\n",
    "from utils.normalizer import persian_normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e84ceb4-8cd5-4061-af51-f12b4c0cecc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T08:16:53.000087Z",
     "iopub.status.busy": "2025-07-08T08:16:52.999862Z",
     "iopub.status.idle": "2025-07-08T08:16:56.579726Z",
     "shell.execute_reply": "2025-07-08T08:16:56.578984Z",
     "shell.execute_reply.started": "2025-07-08T08:16:53.000065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "from jiwer import wer\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d625a45-2f9c-4d8f-97b0-2bec958d2d5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T08:16:56.580545Z",
     "iopub.status.busy": "2025-07-08T08:16:56.580149Z",
     "iopub.status.idle": "2025-07-08T08:16:58.755176Z",
     "shell.execute_reply": "2025-07-08T08:16:58.754472Z",
     "shell.execute_reply.started": "2025-07-08T08:16:56.580532Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "model_id = \"openai/whisper-large-v3\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, \n",
    "    # low_cpu_mem_usage=True, use_safetensors=True\n",
    ").to(device)\n",
    "del model.generation_config.forced_decoder_ids\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "033af508-f8b1-4a7e-a7e4-0c8c68a3da43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T08:16:58.755614Z",
     "iopub.status.busy": "2025-07-08T08:16:58.755500Z",
     "iopub.status.idle": "2025-07-08T08:16:59.858533Z",
     "shell.execute_reply": "2025-07-08T08:16:59.857547Z",
     "shell.execute_reply.started": "2025-07-08T08:16:58.755604Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"hsekhalilian/commonvoice\", split=\"dev\")\n",
    "dataset = dataset.select(range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd0bb76-4843-4e96-b320-aa7433d9609a",
   "metadata": {},
   "source": [
    "# one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2dabe5d-1cf1-4841-b180-6f8e55367ccc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T08:16:59.860384Z",
     "iopub.status.busy": "2025-07-08T08:16:59.860155Z",
     "iopub.status.idle": "2025-07-08T08:17:01.778544Z",
     "shell.execute_reply": "2025-07-08T08:17:01.777849Z",
     "shell.execute_reply.started": "2025-07-08T08:16:59.860362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  این اولین قدم برای تغییر خودم\n",
      "Reference: این اولین قدم برای تغییر خودم\n"
     ]
    }
   ],
   "source": [
    "# Load one sample\n",
    "sample = dataset[0]\n",
    "result = pipe(sample[\"audio\"], generate_kwargs={\"task\": \"transcribe\", \"language\": \"persian\"})\n",
    "\n",
    "# Print results\n",
    "print(\"Prediction:\", result[\"text\"])\n",
    "print(\"Reference:\", sample[\"sentence\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a6bdb1-be8f-4699-a36c-e890f0d0cc1e",
   "metadata": {},
   "source": [
    "# for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3d5d970-4bcd-41ac-bd12-0e695a6bb598",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T08:17:01.780798Z",
     "iopub.status.busy": "2025-07-08T08:17:01.780671Z",
     "iopub.status.idle": "2025-07-08T08:18:21.088387Z",
     "shell.execute_reply": "2025-07-08T08:18:21.087664Z",
     "shell.execute_reply.started": "2025-07-08T08:17:01.780787Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "100%|██████████| 100/100 [01:19<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WER: 38.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "references = []\n",
    "\n",
    "for sample in tqdm(dataset):\n",
    "    result = pipe(sample[\"audio\"], generate_kwargs={\"task\": \"transcribe\", \"language\": \"persian\"})\n",
    "    predictions.append(persian_normalizer(result[\"text\"]))\n",
    "    references.append(sample[\"normalized_transcription\"])\n",
    "\n",
    "# Compute WER\n",
    "error_rate = wer(references, predictions)\n",
    "print(f\"\\nWER: {error_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f02f6aec-a81e-4817-809c-9715eb344f36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T08:14:08.811593Z",
     "iopub.status.busy": "2025-07-08T08:14:08.811302Z",
     "iopub.status.idle": "2025-07-08T08:14:08.820595Z",
     "shell.execute_reply": "2025-07-08T08:14:08.819722Z",
     "shell.execute_reply.started": "2025-07-08T08:14:08.811571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference: این اولین قدم برای تغییر خودم\n",
      "predicted: این اولین قدم برای تغییر خودم\n",
      "------------------------------\n",
      "reference: با خنده ای ترسناک چرا وحشت کردین؟ چرا تهمت می زنی؟\n",
      "predicted: با خنده ترسناک چرا وحشت کردین؟ چرا تهمت میزنین؟\n",
      "------------------------------\n",
      "reference: من همه جا دنبالت گشتم\n",
      "predicted: من همه جا دنبالت گشتم\n",
      "------------------------------\n",
      "reference: افسانهها میگن سگها واسطهی دنیای زندهها با مردههان\n",
      "predicted: افثانه ها میگن تکا وسط دنیا زنده ها با مرده ها\n",
      "------------------------------\n",
      "reference: فر می کنم همین جا باید تمومش کنیم\n",
      "predicted: فکر می کنم همینجا باید تمومش کنیم\n",
      "------------------------------\n",
      "reference: افراسیاب\n",
      "predicted: افراسیاب\n",
      "------------------------------\n",
      "reference: طاهره چی بهش گفتی رنگش پرید\n",
      "predicted: تا هر چی بهش گفتی رنگست برید؟\n",
      "------------------------------\n",
      "reference: من شبا خواب میبینم که سگها به هم حمله میکنن\n",
      "predicted: من شبا خواب میبینم که سگا به هم حمله میکنه\n",
      "------------------------------\n",
      "reference: از وقتی که فقط پنج سالت بود وضع همین بود\n",
      "predicted: از وقتی که فقط پنج سالت بود و از همین بود.\n",
      "------------------------------\n",
      "reference: دانیال به سمت وان میرود\n",
      "predicted: دانیال به سمت وام می روید.\n",
      "------------------------------\n",
      "reference: برای کسایی که تنها زندگی میکنن بهترین همدم گل و گیاهه سرگرمشون میکنه\n",
      "predicted: برای کسی که تنها زندگی می کنند، بهترین حمدم گل و گیاه سرگرمشون می کنند.\n",
      "------------------------------\n",
      "reference: اگه شرایط بد شد یه تیر بزن توی کتف راستت اینجوری مجبورن برگردوننت عقب\n",
      "predicted: اگر صراحه 500 یک چیز بزن توی یک ترس اینجوری مجبور ها برگردونه نترن\n",
      "------------------------------\n",
      "reference: شنید\n",
      "predicted: شنید\n",
      "------------------------------\n",
      "reference: بخورن، گوشت قرمز، پروتئین توی این گرما اور می پوشه\n",
      "predicted: بخورم گوشت قرمز پروتین تو این گرمه اوور میپوسته.\n",
      "------------------------------\n",
      "reference: خود را از وان بیرون می کشد و کنار وان مینشیند\n",
      "predicted: خود را از دان بیرون می کشد و کنار بان می نشیند.\n",
      "------------------------------\n",
      "reference: هیچ وقت زیر قولت نزن من از آدمای بدقول بدم مییاد\n",
      "predicted: هیچ وقت زیرا گلت نزدن و از آدم های بدگل بدم میاد.\n",
      "------------------------------\n",
      "reference: پدر از تخت پایین میآید عصا را باز میکند\n",
      "predicted: پدر از سخت پایین می آید، اثارا باز می کند.\n",
      "------------------------------\n",
      "reference: وظیفت چیه؟ خوردن و خوابیدن؟ این جلف بازیا رو بزار کنار به فکر یه لقمه نون باش.\n",
      "predicted: وظیفت چیه؟ خوردن و خابیدن؟ این جلدبازی ها رو بذار کنار به فکر یه لغم نون باش؟\n",
      "------------------------------\n",
      "reference: من باید باهات حرف بزنم\n",
      "predicted: من باید با آت حرف بزنم.\n",
      "------------------------------\n",
      "reference: می خواد استفاده کنه ؟\n",
      "predicted: میخواد استفاده کنه؟\n",
      "------------------------------\n",
      "reference: لطفا صبحانه ام را ساعت هفت بفرستید.\n",
      "predicted: لطفا صبحانه امروز ساعت هفت بفرستید.\n",
      "------------------------------\n",
      "reference: من هر چیزی شما توصیه کنید می خورم.\n",
      "predicted: من هر چیزی شما توصیه می کنید می خورم\n",
      "------------------------------\n",
      "reference: شب فوق العاده ای است.\n",
      "predicted: شب فونگلاده ای هست\n",
      "------------------------------\n",
      "reference: من با یک ماشین تصادف کرده ام.\n",
      "predicted: من با یک ماشین تصادف کردم.\n",
      "------------------------------\n",
      "reference: بخش مواد غذایی در کدام طبقه است؟\n",
      "predicted: بخش مواد نقضایی در کدام طبقه هست؟\n",
      "------------------------------\n",
      "reference: در این میان هیچ کسی به کیف های شما دسترسی داشته است؟\n",
      "predicted: در این میان هیچ کسی به کیفهای شما دسترسی داشته است؟\n",
      "------------------------------\n",
      "reference: آمده ام کامپیوترم را بگیرم.\n",
      "predicted: آمدم کامپیوترم را بگیرم.\n",
      "------------------------------\n",
      "reference: آیا می تواند دوباره صادر شود؟\n",
      "predicted: آیا می تواند دوباره ساده شود؟\n",
      "------------------------------\n",
      "reference: من فقط خیلی کم هلندی صحبت می کنم.\n",
      "predicted: من فقط خیلی کم هولندی صحبت میکنم\n",
      "------------------------------\n",
      "reference: زندگی آپارتمانی\n",
      "predicted: زندگی اپارتمانی\n",
      "------------------------------\n",
      "reference: برگها از درختان آویزان بودند.\n",
      "predicted: برک ها از درختان آویزان بودند.\n",
      "------------------------------\n",
      "reference: استتار ما را آشکار کردند.\n",
      "predicted: استطاره ما را آشکار کردند.\n",
      "------------------------------\n",
      "reference: تازه از دانشگاه درآمده بودم و دلم برای مسافرت لک میزد.\n",
      "predicted: تازه از دانشگاه در آمده بودم و دلم برای مسافرت لک می زد.\n",
      "------------------------------\n",
      "reference: ساتن پارچهای نرم و براق است.\n",
      "predicted: ساتن پارچه نرم و براغ است.\n",
      "------------------------------\n",
      "reference: حرفهای حاکی از نومیدی او\n",
      "predicted: حقای حاکی از نامیدیه او\n",
      "------------------------------\n",
      "reference: او خیلی به خودش مینازد.\n",
      "predicted: او خیلی به خودش می نازد.\n",
      "------------------------------\n",
      "reference: به مصداق\n",
      "predicted: دمستا\n",
      "------------------------------\n",
      "reference: به خاطر حسادت\n",
      "predicted: به خاطر حسادت\n",
      "------------------------------\n",
      "reference: حساب راکد\n",
      "predicted: حساب راکب\n",
      "------------------------------\n",
      "reference: متاسفانه نمیتوانم بروم.\n",
      "predicted: متاسفانه نمیتوانم برابرم.\n",
      "------------------------------\n",
      "reference: او هنوز از نظر حرفهای به جایی نرسیده است.\n",
      "predicted: او هنوز از نظر حرفه ای به جایی نرسیده است.\n",
      "------------------------------\n",
      "reference: خروش جنگ\n",
      "predicted: خروش جاییم\n",
      "------------------------------\n",
      "reference: رودررویی مصممانه\n",
      "predicted: رودرویه مسممانه\n",
      "------------------------------\n",
      "reference: ولی دیگر لگو نخواهد بود.\n",
      "predicted: ولی دیگر لگو نخواهد بود.\n",
      "------------------------------\n",
      "reference: لینوکس چند سالی بیشتر نیست که به شکل جدی وارد دنیای دسکتاپ شده است.\n",
      "predicted: لینوکس چند سالی بیشتر نیست که به شکل جدی وارد دنیای دسکتاب شده است.\n",
      "------------------------------\n",
      "reference: تو بدری و خورشید تو را بنده شدهست\n",
      "predicted: تو بدری و خوشی تو را بنده شده است\n",
      "------------------------------\n",
      "reference: بخصوص اگر این دوچرخه اول شما است، زیاد هزینه نکنید.\n",
      "predicted: به خصوص اگر این دو شرخه اول شماست زیاد حضینه نکنید\n",
      "------------------------------\n",
      "reference: دوچرخه ابزاری فوق العاده است.\n",
      "predicted: تو چخه عبزایی فغراده است؟\n",
      "------------------------------\n",
      "reference: شکل بدنه و زوایای قرار گیری بدن، فاکتور اول مشخص کننده راحتی هستند.\n",
      "predicted: شکل بدن و زبایه قراری بدن فکتور اول مشخص کننده راحتی هستند.\n",
      "------------------------------\n",
      "reference: یادگیری زبان برنامه نویسی مانند یادگیری نوشتن یک زبان واقعی است.\n",
      "predicted: یادگیری زبان برنامه نویسی مانند یادگیری نوشتن یک زبان واقعی است.\n",
      "------------------------------\n",
      "reference: این مشکل حالا تا حد زیادی مرتفع شده.\n",
      "predicted: این مشکل حالا تا حد زیادی مرتفع شده\n",
      "------------------------------\n",
      "reference: زمان شما،\n",
      "predicted: زمان شما\n",
      "------------------------------\n",
      "reference: زبانهای دیگری هستند که ارزش خاصی برای هکرها دارند.\n",
      "predicted: زبان های دیگری هستند که عرضش خاصی برای هکر ها دارند.\n",
      "------------------------------\n",
      "reference: بخصوص وقتی مطمئن نیستید کدامش برای شما بهتر است.\n",
      "predicted: به خصوص وقتی مطمئن نیستید کدامش برای شما بهتر است.\n",
      "------------------------------\n",
      "reference: خوشبختانه ایران هنوز جزو این جاها نیست.\n",
      "predicted: خوشبختانه ایران هنوز جزو این جهان نیست.\n",
      "------------------------------\n",
      "reference: آنها بعد از ماه ها و حتی سال ها که از شما خبری ندارند\n",
      "predicted: آنها بعد از ماه ها و حتی سال ها که از شما خبری ندارند\n",
      "------------------------------\n",
      "reference: حال من خوب است اما با تو بهتر میشوم\n",
      "predicted: حال من خوب است اما با تو بهتر می شدم\n",
      "------------------------------\n",
      "reference: نه شغلی، نه دوست پسری\n",
      "predicted: نه شغلی نه دوست بسری\n",
      "------------------------------\n",
      "reference: ال:برای اون سه تا مانتو،سه تا کیف و کفش و روسری جدا بگیرم\n",
      "predicted: ال برای اون سه تا منتو سه تا کیف و کف رو رو سهری جدا بگیرم.\n",
      "------------------------------\n",
      "reference: اون هنوز متوجه نشده\n",
      "predicted: اون هنوز متوجه نشده\n",
      "------------------------------\n",
      "reference: تا دستم را برای برداشتن یکی از سیگارهایش دراز کردم مچم را گرفت.\n",
      "predicted: تا دستم را برای برداشتن یکی از سیگارهایش درست کردم، مچم را گرفت.\n",
      "------------------------------\n",
      "reference: اسب زیر بار سنگین میلنگید.\n",
      "predicted: اصب زیر بار سنگین میلنگید\n",
      "------------------------------\n",
      "reference: آن شغل را به خاطر توصیهی شما بدست آورد.\n",
      "predicted: آن شغرا به خاطر توصیه شما به دست آوند.\n",
      "------------------------------\n",
      "reference: نظریه شمادر این باب چیست\n",
      "predicted: نظریه شما در این باب چیست؟\n",
      "------------------------------\n",
      "reference: برخی تشکها فنر دارند.\n",
      "predicted: برخی توشک ها فنر دارند.\n",
      "------------------------------\n",
      "reference: پس از سی سال زحمت شاهنامه را تمام کرد.\n",
      "predicted: پس از سی سال زحمت شاهنامه را تمام کرد.\n",
      "------------------------------\n",
      "reference: اصول بنیادی علوم و ادبیات\n",
      "predicted: اصول بنیادی علوم و عدبیت\n",
      "------------------------------\n",
      "reference: آنها مطیعانه به محل اعدام خود رفتند.\n",
      "predicted: آنها متیانه به محل اعدام خود رفتند.\n",
      "------------------------------\n",
      "reference: هر وقت دلم می گرفت\n",
      "predicted: هر وقت دلم می گرفت\n",
      "------------------------------\n",
      "reference: نقل شده\n",
      "predicted: نقل شده\n",
      "------------------------------\n",
      "reference: متصاعد\n",
      "predicted: متساعد\n",
      "------------------------------\n",
      "reference: آیا من یه احمق هستم؟\n",
      "predicted: آیا من احمق هستم؟\n",
      "------------------------------\n",
      "reference: و روشی که پول در میآورند، روشی که ارزش خلق میکنند،\n",
      "predicted: و روشی که پول در می آورند روشی که عزش خلق می کنند.\n",
      "------------------------------\n",
      "reference: اول آنکه چه اتفاقی افتاد؟\n",
      "predicted: اولان که چه تفاقی افتاد.\n",
      "------------------------------\n",
      "reference: دنیای سگا خیلی باحاله\n",
      "predicted: دنیا یه سگا خیلی باحاله\n",
      "------------------------------\n",
      "reference: بله بله ، مانیکا لاغره\n",
      "predicted: بله بله مالیکا لاغره\n",
      "------------------------------\n",
      "reference: بدمیگم؟\n",
      "predicted: بعد میگه\n",
      "------------------------------\n",
      "reference: چطور فهمیدی من اینجام؟\n",
      "predicted: چطور فهمیدیم اینجا؟\n",
      "------------------------------\n",
      "reference: چرا اول به خودم نگفت ؟\n",
      "predicted: چرا اول به خودم نگفت؟\n",
      "------------------------------\n",
      "reference: که هر وقتی کسی خواست چیزی رو از کسی مخفی کنه\n",
      "predicted: که هر وقت کسی خواست چیزی رو از کسی مخفی کنه\n",
      "------------------------------\n",
      "reference: شروع میکنه به داد زدن.\n",
      "predicted: شروع میکنه به داد زدن\n",
      "------------------------------\n",
      "reference: آقا، امروز کمک نمی خواین؟\n",
      "predicted: آقا، امبوس کمک نمی خواهید؟\n",
      "------------------------------\n",
      "reference: امیرحسن\n",
      "predicted: امیر حسن\n",
      "------------------------------\n",
      "reference: و به مطالعه تطبیقی آثار برخاسته از فرهنگ های گوناگون می پردازد\n",
      "predicted: و به متعلقه تطبیقی آثار برخواسته از فرهنگ های گناگون می پردازد.\n",
      "------------------------------\n",
      "reference: اهورا\n",
      "predicted: اهورا\n",
      "------------------------------\n",
      "reference: نگاه داشت\n",
      "predicted: نگاه داشت\n",
      "------------------------------\n",
      "reference: چهارصد\n",
      "predicted: چهار ست\n",
      "------------------------------\n",
      "reference: مسقط\n",
      "predicted: مسقط\n",
      "------------------------------\n",
      "reference: پاراماریبو\n",
      "predicted: پراماریبو\n",
      "------------------------------\n",
      "reference: برازنده\n",
      "predicted: برازنده\n",
      "------------------------------\n",
      "reference: برشام\n",
      "predicted: برشام\n",
      "------------------------------\n",
      "reference: اکرام\n",
      "predicted: اکرام\n",
      "------------------------------\n",
      "reference: عبارتی گفته میشود تا طرف را از یک نقطه به نقطه دیگر اتصال دهد\n",
      "predicted: عبارتی گفته می شود تا طرف رو از یک نقطه به نقطه دیگر اتصال دهد\n",
      "------------------------------\n",
      "reference: فراز رفت\n",
      "predicted: فروز رفت\n",
      "------------------------------\n",
      "reference: .یه شام مختصر درست کنه\n",
      "predicted: اشغام مختصر درست کنم\n",
      "------------------------------\n",
      "reference: یه بار تو محدوده مون یه دختر پسر در حال ماچ کردن هم بودن\n",
      "predicted: یه بار تو محدودمون یه دختر پسر دقیقا ماش کردن هم بودن\n",
      "------------------------------\n",
      "reference: .اوه ، خوب پس الان نه\n",
      "predicted: او خب پس الان نه\n",
      "------------------------------\n",
      "reference: آره اون الان زندانی منه\n",
      "predicted: آقا اون اعلان زندنی منه\n",
      "------------------------------\n",
      "reference: تو نمی خوای بازی کنی ؟\n",
      "predicted: تو نمیخوای بازی کنی؟\n",
      "------------------------------\n",
      "reference: خیر نبینی چه جوری برداشتی که من ندیدم؟\n",
      "predicted: خیلی نبینید چجوری برداشتی که من ندیدم؟\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for reference, prediction in zip(references, predictions):\n",
    "    print(f\"reference: {reference}\")\n",
    "    print(f\"predicted: {prediction}\")\n",
    "    print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c6fc42-bbd8-4e7a-942c-36c4dee78a0a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# huggingface datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03a139aa-1135-4ac8-a490-66376c96c736",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T08:18:52.939255Z",
     "iopub.status.busy": "2025-07-08T08:18:52.938938Z",
     "iopub.status.idle": "2025-07-08T08:20:25.868198Z",
     "shell.execute_reply": "2025-07-08T08:20:25.867387Z",
     "shell.execute_reply.started": "2025-07-08T08:18:52.939232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c6fa70a8434b4c852964308a25a570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WER: 39.97%\n"
     ]
    }
   ],
   "source": [
    "def transcribe(sample):\n",
    "    result = pipe(sample[\"audio\"], return_timestamps=True, generate_kwargs={\"task\": \"transcribe\", \"language\": \"persian\"})\n",
    "    sample[\"prediction\"] = persian_normalizer(result[\"text\"])\n",
    "    \n",
    "    return sample\n",
    "\n",
    "processed_dataset = dataset.map(transcribe, batched=False)\n",
    "\n",
    "references = processed_dataset[\"normalized_transcription\"]\n",
    "predictions = processed_dataset[\"prediction\"]\n",
    "\n",
    "error_rate = wer(references, predictions)\n",
    "print(f\"\\nWER: {error_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0e25ea4-003d-498d-8494-6584dd61f95a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T08:24:26.467822Z",
     "iopub.status.busy": "2025-07-08T08:24:26.467497Z",
     "iopub.status.idle": "2025-07-08T08:25:57.997242Z",
     "shell.execute_reply": "2025-07-08T08:25:57.996583Z",
     "shell.execute_reply.started": "2025-07-08T08:24:26.467800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9020acaad8a41a8ae987c159a4221e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WER: 39.97%\n"
     ]
    }
   ],
   "source": [
    "def transcribe_batch(batch):\n",
    "    results = pipe(\n",
    "        batch[\"audio\"],\n",
    "        return_timestamps=True,\n",
    "        generate_kwargs={\"task\": \"transcribe\", \"language\": \"persian\"}\n",
    "    )\n",
    "    # Handle both single and batched outputs\n",
    "    if isinstance(results, dict):\n",
    "        texts = [persian_normalizer(results[\"text\"])]\n",
    "    else:\n",
    "        texts = [persian_normalizer(result[\"text\"]) for result in results]\n",
    "    batch[\"prediction\"] = texts\n",
    "    return batch\n",
    "\n",
    "# Apply batched processing (batch size = 8, can be tuned)\n",
    "processed_dataset = dataset.map(\n",
    "    transcribe_batch,\n",
    "    batched=True,\n",
    "    batch_size=4,\n",
    ")\n",
    "\n",
    "# Compute WER\n",
    "references = processed_dataset[\"normalized_transcription\"]\n",
    "predictions = processed_dataset[\"prediction\"]\n",
    "error_rate = wer(references, predictions)\n",
    "print(f\"\\nWER: {error_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33d2b3c-96be-4db1-bb12-05803a971b54",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1490ba54-ccdc-40f8-aa90-10f87dd307f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T08:15:21.306716Z",
     "iopub.status.busy": "2025-07-08T08:15:21.306430Z",
     "iopub.status.idle": "2025-07-08T08:15:25.263275Z",
     "shell.execute_reply": "2025-07-08T08:15:25.262654Z",
     "shell.execute_reply.started": "2025-07-08T08:15:21.306694Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.\n",
      "Transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English. This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`. See https://github.com/huggingface/transformers/pull/28687 for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel. Nor is Mr. Quilter's manner less interesting than his matter. He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similes drawn from eating and its results occur most readily to the mind. He has grave doubts whether Sir Frederick Layton's work is really Greek after all, and can discover in it but little of rocky Ithaca. Linnell's pictures are a sort of Up Guards and Adam paintings, and Mason's exquisite idles are as national as a jingo poem. Mr. Birkett Foster's landscapes smile at one much in the same way that Mr. Carker used to flash his teeth, and Mr. John Collier gives his sitter a cheerful slap on the back before he says like a shampooer in a Turkish bath next man\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-large-v3-turbo\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")\n",
    "sample = dataset[0][\"audio\"]\n",
    "\n",
    "# 🔧 Fix: Enable timestamps for long-form audio\n",
    "result = pipe(sample, return_timestamps=True)\n",
    "\n",
    "# If you only want the text\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e18fa27-8ee0-49ca-ade3-44c60557e627",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T08:33:37.665354Z",
     "iopub.status.busy": "2025-07-08T08:33:37.665189Z",
     "iopub.status.idle": "2025-07-08T08:33:52.602221Z",
     "shell.execute_reply": "2025-07-08T08:33:52.601523Z",
     "shell.execute_reply.started": "2025-07-08T08:33:37.665340Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Using `chunk_length_s` is very experimental with seq2seq models. The results will not necessarily be entirely accurate and will have caveats. More information: https://github.com/huggingface/transformers/pull/20104. Ignore this warning with pipeline(..., ignore_warning=True). To use Whisper for long-form transcription, use rather the model's `generate` method directly as the model relies on it's own chunking mechanism (cf. Whisper original paper, section 3.8. Long-form Transcription).\n",
      "/opt/conda/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:604: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.\n",
      "Transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English. This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`. See https://github.com/huggingface/transformers/pull/28687 for more details.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel. Nor is Mr. Quilter's manner less interesting than his matter. He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similes drawn from eating and its results occur most readily to the mind. He has grave doubts whether Sir Frederick Leighton's work is really Greek after all, and can discover in it but little of rocky Ithaca. Linnell's pictures are a sort of Upguards and Adam paintings, and Mason's exquisite idylls are as national as a jingo poem. Mr. Burkett Foster's landscapes smile at one much in the same way that Mr. Carker used to flash his teeth. And Mr. John Collier gives his sitter a cheerful slap on the back before he says, like a shampooer in a Turkish bath, Next man!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=16,  # batch size for inference - set based on your device\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")\n",
    "sample = dataset[0][\"audio\"]\n",
    "\n",
    "result = pipe(sample)\n",
    "print(result[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929ffc45-6e36-45ba-a350-3f821c1f3056",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
